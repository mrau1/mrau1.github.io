{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The aim of this project is to examine the relationships between major coronavirus events and their impact on various economies.\n",
    "\n",
    "***I do not have a partner. I reached out to multiple people, however, it was already too late. \n",
    "   Somebody came to me and like my topic, however, he could not get out of his current situation. ***\n",
    "\n",
    "Major events are outlined from the CoronaNet Project https://www.coronanet-project.org/download.html. This data set includes coronavirus events for 35+ countries from January 2020 - August 2020. This data set is updated monthly and is redownloaded as such.\n",
    "\n",
    "The first step in this process is to analyze what is a \"good\" vs. \"bad\" event. I will take key words, phrases that are justifiably bad, \"State of emergency\", \"implement lockdown\", \"lifts lockdown\", or \"imposes\"\n",
    "\n",
    "Two comparisons will be examined\n",
    "    1: Country vs. Country\n",
    "    2: Country vs. Benchmark Indices.\n",
    "    \n",
    "In country vs. country analyses, I will be looking at the effect on exchange rates. I will take major events in one economy and see how it shifts exchange rates before and after. I want to see if there is a devaluation in currency not due to a forcasted drop in interest rates, nor an influx due to a stable balance sheet, but due to immediate investor reaction to a governments handling of the crisis. This will account the economic outlook of a nation in reaction to a major event.\n",
    "\n",
    "In country vs. benchmark, I will take each country's major events and analyze how their respective stock markets react. For instance, in the United States, I would analyze how the Dow Jones, S&P 500, Russell 2000, and VIX moves in relation to big events. I have compiled a csv file with each countries benchmark index and their https://finance.yahoo.com/ tickers. The CSV file contains 14 different countries indices. \n",
    "\n",
    "I have already written code that webscrapes historical data from https://finance.yahoo.com/. I will use this end of day and opening price data to see major shifts in economic outlook resulting from a major event. I will use the requests library to scrape this data.\n",
    "    - https://finance.yahoo.com/ loves to use excessive JSON's in the back of their html pages and can be used as such.\n",
    "   \n",
    "Steps:\n",
    "\n",
    "1: Clean Data\n",
    "2: Determine good vs. bad events in the description\n",
    "3: Determine gravity of each event (coronvirus shutdown in 1 state -> combine events into \"multiple states shut down\")\n",
    "4: Make boolean table on when each country has major events -> used to determine coincidences/possible biased results.\n",
    "5: Take average price levels for indices and foreign exchange rates, and look for immediate/delayed price movement.\n",
    "    - Put emphasis on countries not experiencing major events and have had their currencies \"normalize\".\n",
    "6. Construct meta-data on the results and construct model to analyze data.\n",
    "\n",
    "Organizational Structure:\n",
    "\n",
    "I plan on pushing my updated code to a github repository so I can work on my project wherever I may be. I do not use the same computer to do all my work and need the flexibility to store my code/data online. If calculations get too large, or I need extra storage space, I plan on setting up an AWS S3 bucket to store my data, or I will use the google drive API to store data in google sheets. I do not anticipate this being the case. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import logging\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import gspread\n",
    "from pprint import pprint\n",
    "from googleapiclient import discovery\n",
    "\"\"\"\n",
    "\n",
    "historical_url = \"https://finance.yahoo.com/quote/%s/history?p=%s\"\n",
    "\n",
    "\n",
    "\"\"\"Adjusted to automatically take in symbols for automation\"\"\"\n",
    "def generateUrl(symbol=False):\n",
    "    url_1 = \"https://finance.yahoo.com/quote/\"\n",
    "    url_2 = \"?p=\"\n",
    "    url_3 = \"&.tsrc=fin-srch\"\n",
    "   \n",
    "    if symbol == False:\n",
    "        # Allows user to input stock symbol and returns the Yahoo finance URL\n",
    "        symbol = input(\"Enter a ticker symbol for a stock: \")\n",
    "        url = url_1 + symbol + url_2 + symbol + url_3\n",
    "    else:\n",
    "        url = url_1 + symbol + url_2 + symbol + url_3\n",
    "       \n",
    "    return url\n",
    "       \n",
    "\"\"\"Adjusted to allow symbols and different URL's to pass through\n",
    "    Allows us to grab from historical, options, and other data sources\"\"\"\n",
    "def dataGrabber(symbol=False, url=None):\n",
    "    if url == None:\n",
    "        # Obtain server's response to HTTP request\n",
    "        url = generateUrl(symbol)\n",
    "       \n",
    "    src = requests.get(url)\n",
    "    # Converts source code to string\n",
    "    data = src.text\n",
    "    return data\n",
    "       \n",
    "\n",
    "\n",
    "def getCurrentPrice(symbol=False):\n",
    "    # Isolates the currentPrice variable\n",
    "    data = dataGrabber(symbol)\n",
    "    split = data.split(\"currentPrice\\\":\", 1)\n",
    "    halfList = split[1]\n",
    "    split2 = halfList.split(\"}\", 1)\n",
    "    currentPrice = split2[0] + \"}\"\n",
    "    finalPrice = currentPrice.split(\"\"\"{\"raw\":\"\"\")[1].split(\",\")[0]\n",
    "    # Print and return current price\n",
    "    print(symbol, finalPrice)\n",
    "    return round(float(finalPrice),3)\n",
    "\n",
    "\n",
    "def getCSV(symbol=None):\n",
    "    # Gets CSV of historical data on stock for the past 5 years\n",
    "    url_1 = \"https://query1.finance.yahoo.com/v7/finance/download/\"\n",
    "    url_2 = \"?period1=1433980800&period2=\" + t\n",
    "    url_3 = \"&interval=1d&events=history\"\n",
    "    if symbol == None:\n",
    "        symbol = input(\"Enter a ticker symbol for a stock: \")\n",
    "    url = url_1 + symbol + url_2 + url_3\n",
    "    print(url)\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(url)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        historical_data = list(cr)\n",
    "        # Prints CSV\n",
    "        c = True\n",
    "       \n",
    "        data = []\n",
    "       \n",
    "        for row in historical_data:\n",
    "            if c == True:\n",
    "                columns = row\n",
    "                c=False\n",
    "            else:\n",
    "                data.append(row)\n",
    "                print(row)\n",
    "        \n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        print(df)\n",
    "       \n",
    "        df.to_csv(symbol + \".csv\")\n",
    "       \n",
    "        # Outputs CSV file to computer\n",
    "        # Filename will be ticker symbol\n",
    "    return\n",
    "\n",
    "def getJSON(symbol, url = historical_url):\n",
    "    url = url % (symbol, symbol)\n",
    "   \n",
    "    data = dataGrabber(url)\n",
    "    start = '''\"HistoricalPriceStore\":{\"prices\":'''\n",
    "    end = \"\"\"]}\"\"\"\n",
    "    print(url)\n",
    "    print(data)\n",
    "   \n",
    "#getCSV('TSLA')\n",
    "   \n",
    "   \n",
    "   \n",
    "def priceToJSON(symbol):\n",
    "    import os\n",
    "   \n",
    "    price = getCurrentPrice(symbol)\n",
    "   \n",
    "    if os.path.exists(symbol + '_current.txt'):\n",
    "        os.remove(symbol + '_current.txt')\n",
    "   \n",
    "   \n",
    "    with open(symbol + '_current.txt', 'x') as inFile:\n",
    "        #df = json.loads(inFile.read())\n",
    "        inFile.write(str(price))\n",
    "   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangladesh imposes restriction on presence of state employees in the offices. Only 25% of the officials are allowed in the offices. Announced on June 01. On August 03, the state minister of Public Administration Ministry has announced to put an end to this requirement. The Orders have been given orally. The full attendance will be ensured from Sunday, August 09.\n"
     ]
    }
   ],
   "source": [
    "corona = pd.read_csv(\"data/coronanet_release.csv\")\n",
    "indices = pd.read_csv(\"data/Stock Market Indices by Country - Sheet1.csv\")\n",
    "\n",
    "print(corona.iloc[643]['description'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
